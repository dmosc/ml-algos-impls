{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scores=[78.43137254901961, 79.73856209150327, 73.20261437908496, 79.08496732026144, 70.58823529411765]'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mean accuracy=76.20915032679738'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import seed, randrange\n",
    "from csv import reader\n",
    "from math import exp\n",
    "\n",
    "\n",
    "seed(42)\n",
    "\n",
    "\n",
    "def load_csv(filepath):\n",
    "  dataset = []\n",
    "\n",
    "  with open(filepath, \"r\") as file:\n",
    "    csv_reader = reader(file)\n",
    "    for row in csv_reader:\n",
    "      if row:\n",
    "        dataset.append(row)\n",
    "  \n",
    "  return dataset\n",
    "\n",
    "\n",
    "def str_col_to_float(dataset, col):\n",
    "  for row in dataset:\n",
    "    row[col] = float(row[col].strip())\n",
    "\n",
    "\n",
    "def dataset_minmax(dataset):\n",
    "  minmax = []\n",
    "\n",
    "  for col in range(len(dataset[0])):\n",
    "    col_vals = list(map(lambda row: row[col], dataset))\n",
    "    minmax.append([min(col_vals), max(col_vals)])\n",
    "\n",
    "  return minmax\n",
    "\n",
    "\n",
    "def dataset_normalize(dataset):\n",
    "  minmax = dataset_minmax(dataset)\n",
    "\n",
    "  for row in dataset:\n",
    "    for i in range(len(row)):\n",
    "      row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "\n",
    "\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "  dataset_folds = []\n",
    "  fold_size = int(len(dataset) / n_folds)\n",
    "  _dataset = dataset.copy()\n",
    "\n",
    "  for _ in range(n_folds):\n",
    "    fold = []\n",
    "    while len(fold) < fold_size:\n",
    "      fold.append(_dataset.pop(randrange(len(_dataset))))\n",
    "    dataset_folds.append(fold)\n",
    "  \n",
    "  return dataset_folds\n",
    "\n",
    "\n",
    "def accuracy_metric(actual, predicted):\n",
    "  assert len(actual) == len(predicted)\n",
    "\n",
    "  size = len(actual)\n",
    "  correct_count = 0\n",
    "\n",
    "  for i in range(size):\n",
    "    correct_count += 1 if actual[i] == predicted[i] else 0\n",
    "  \n",
    "  return (correct_count / size) * 100.0\n",
    "\n",
    "\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "  folds = cross_validation_split(dataset=dataset, n_folds=n_folds)\n",
    "  scores = []\n",
    "\n",
    "  for fold in folds:\n",
    "    train = folds.copy()\n",
    "    train.remove(fold)\n",
    "    train = sum(train, [])\n",
    "    test = []\n",
    "    for row in fold:\n",
    "      _row = row.copy()\n",
    "      _row[-1] = None\n",
    "      test.append(_row)\n",
    "    predicted = algorithm(train, test, *args)\n",
    "    actual = list(map(lambda row: row[-1], fold))\n",
    "    scores.append(accuracy_metric(actual=actual, predicted=predicted))\n",
    "\n",
    "  return scores\n",
    "\n",
    "\n",
    "def predict(row, coefs):\n",
    "  yhat = coefs[0]\n",
    "  \n",
    "  for i in range(len(row) - 1):\n",
    "    yhat += coefs[i + 1] * row[i]\n",
    "  \n",
    "  return 1.0 / (1.0 + exp(-yhat))\n",
    "\n",
    "\n",
    "def coefficients_sdg(train, l_rate, n_epochs):\n",
    "  coefs = [0.0] * len(train[0])\n",
    "  \n",
    "  for epoch in range(n_epochs):\n",
    "    for row in train:\n",
    "      yhat = predict(row=row, coefs=coefs)\n",
    "      error = row[-1] - yhat\n",
    "      coefs[0] = coefs[0] + l_rate * error * yhat * (1.0 - yhat)\n",
    "      for i in range(len(row) - 1):\n",
    "        coefs[i + 1] = coefs[i + 1] + l_rate * error * yhat * (1.0 - yhat) * row[i]\n",
    "  \n",
    "  return coefs\n",
    "\n",
    "\n",
    "def logistic_regression(train, test, l_rate, n_epochs):\n",
    "  predictions = []\n",
    "  coefs = coefficients_sdg(train=train, l_rate=l_rate, n_epochs=n_epochs)\n",
    "\n",
    "  for row in test:\n",
    "    yhat = round(predict(row=row, coefs=coefs))\n",
    "    predictions.append(yhat)\n",
    "  \n",
    "  return predictions\n",
    "\n",
    "filepath = \"../datasets/pima-indians-diabetes.csv\"\n",
    "dataset = load_csv(filepath=filepath)\n",
    "for i in range(len(dataset[0])):\n",
    "  str_col_to_float(dataset=dataset, col=i)\n",
    "dataset_normalize(dataset=dataset)\n",
    "n_folds = 5\n",
    "l_rate = 0.1\n",
    "n_epochs = 100\n",
    "scores = evaluate_algorithm(dataset, logistic_regression, n_folds, l_rate, n_epochs)\n",
    "display(f\"scores={scores}\")\n",
    "display(f\"mean accuracy={sum(scores) / float(len(scores))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d90add59a33e9f0fdc2a403872f22c3f38cf2bdffc6f1ab0ac261e13b4722f13"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
