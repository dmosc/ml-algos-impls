{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from random import randrange, seed\n",
    "from csv import reader\n",
    "\n",
    "\n",
    "seed(42)\n",
    "\n",
    "\n",
    "def load_csv(filepath):\n",
    "  dataset = []\n",
    "\n",
    "  with open(filepath, \"r\") as file:\n",
    "    csv_reader = reader(file)\n",
    "    for row in csv_reader:\n",
    "      if row:\n",
    "        dataset.append(row)\n",
    "  \n",
    "  return dataset\n",
    "\n",
    "\n",
    "def str_col_to_float(dataset, col):\n",
    "  for row in dataset:\n",
    "    row[col] = float(row[col].strip())\n",
    "\n",
    "\n",
    "def str_col_to_int(dataset, col):\n",
    "  class_vals = set(list(map(lambda row: row[-1], dataset)))\n",
    "  class_lookup = {}\n",
    "\n",
    "  for i, val in enumerate(class_vals):\n",
    "    class_lookup[val] = i\n",
    "  for row in dataset:\n",
    "    row[col] = class_lookup[row[col]]\n",
    "  \n",
    "  return class_lookup\n",
    "\n",
    "\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "  dataset_folds = []\n",
    "  fold_size = int(len(dataset) / n_folds)\n",
    "  dataset_ = dataset.copy()\n",
    "\n",
    "  for _ in range(n_folds):\n",
    "    fold = []\n",
    "    while len(fold) < fold_size:\n",
    "      fold.append(dataset_.pop(randrange(len(dataset_))))\n",
    "    dataset_folds.append(fold)\n",
    "  \n",
    "  return dataset_folds\n",
    "\n",
    "\n",
    "def accuracy_metric(actual, predicted):\n",
    "  assert len(actual) == len(predicted)\n",
    "\n",
    "  size = len(actual)\n",
    "  correct_count = 0\n",
    "\n",
    "  for i in range(size):\n",
    "    correct_count += 1 if actual[i] == predicted[i] else 0\n",
    "\n",
    "  return (correct_count / float(size)) * 100\n",
    "\n",
    "\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "  folds = cross_validation_split(dataset=dataset, n_folds=n_folds)\n",
    "  scores = []\n",
    "\n",
    "  for fold in folds:\n",
    "    train = folds.copy()\n",
    "    train.remove(fold)\n",
    "    train = sum(train, [])\n",
    "    test = []\n",
    "    for row in fold:\n",
    "      row_ = row.copy()\n",
    "      row_[-1] = None\n",
    "      test.append(row_)\n",
    "    predicted = algorithm(train, test, *args)\n",
    "    actual = list(map(lambda row: row[-1], fold))\n",
    "    accuracy = accuracy_metric(actual=actual, predicted=predicted)\n",
    "    scores.append(accuracy)\n",
    "  \n",
    "  return scores\n",
    "\n",
    "\n",
    "def euclidean_distance(row1, row2):\n",
    "  assert len(row1) == len(row2)\n",
    "\n",
    "  distance = 0.0\n",
    "\n",
    "  for i in range(len(row1) - 1):\n",
    "    distance += pow(row1[i] - row2[i], 2)\n",
    "  \n",
    "  return sqrt(distance)\n",
    "\n",
    "\n",
    "def get_best_matching_unit(codebooks, row):\n",
    "  distances = []\n",
    "\n",
    "  for codebook in codebooks:\n",
    "    dist = euclidean_distance(row1=codebook, row2=row)\n",
    "    distances.append((codebook, dist))\n",
    "  distances.sort(key=lambda tup: tup[1])\n",
    "\n",
    "  return distances[0][0]\n",
    "\n",
    "\n",
    "def predict(codebooks, row):\n",
    "  bmu = get_best_matching_unit(codebooks=codebooks, row=row)\n",
    "  return bmu[-1]\n",
    "\n",
    "\n",
    "def random_codebook(train):\n",
    "  n_records = len(train)\n",
    "  n_features = len(train[0])\n",
    "\n",
    "  codebook = [train[randrange(n_records)][i] for i in range(n_features)]\n",
    "\n",
    "  return codebook\n",
    "\n",
    "\n",
    "def train_codebooks(train, n_codebooks, l_rate, n_epochs):\n",
    "  codebooks = [random_codebook(train=train) for _ in range(n_codebooks)]\n",
    "\n",
    "  for epoch in range(n_epochs):\n",
    "    rate = l_rate * (1 - (epoch / float(n_epochs)))\n",
    "    error_sum = 0.0\n",
    "    for row in train:\n",
    "      bmu = get_best_matching_unit(codebooks=codebooks, row=row)\n",
    "      for i in range(len(row) - 1):\n",
    "        error = row[i] - bmu[i]\n",
    "        error_sum += pow(error, 2)\n",
    "        if bmu[-1] == row[-1]:\n",
    "          bmu[i] += rate * error\n",
    "        else:\n",
    "          bmu[i] -= rate * error\n",
    "    # print(f\"epoch={epoch}; l_rate={l_rate}; error={error_sum:.2f}\")\n",
    "  \n",
    "  return codebooks\n",
    "\n",
    "\n",
    "def learning_vector_quantization(train, test, n_codebooks, l_rate, n_epochs):\n",
    "  codebooks = train_codebooks(train=train, n_codebooks=n_codebooks, l_rate=l_rate, n_epochs=n_epochs)\n",
    "  predictions = []\n",
    "\n",
    "  for row in test:\n",
    "    predictions.append(predict(codebooks=codebooks, row=row))\n",
    "  \n",
    "  return predictions\n",
    "\n",
    "\n",
    "filepath = \"../datasets/ionosphere.csv\"\n",
    "dataset = load_csv(filepath=filepath)\n",
    "for i in range(len(dataset[0]) - 1):\n",
    "  str_col_to_float(dataset=dataset, col=i)\n",
    "str_col_to_int(dataset=dataset, col=len(dataset[0]) - 1)\n",
    "l_rate = 0.3\n",
    "n_folds = 5\n",
    "n_epochs = 50\n",
    "n_codebooks = 20\n",
    "scores = evaluate_algorithm(dataset, learning_vector_quantization, n_folds, n_codebooks, l_rate, n_epochs)\n",
    "display(f\"scores={scores}\")\n",
    "display(f\"mean accuracy={sum(scores) / len(scores)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d90add59a33e9f0fdc2a403872f22c3f38cf2bdffc6f1ab0ac261e13b4722f13"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
