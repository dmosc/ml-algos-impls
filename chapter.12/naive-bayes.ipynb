{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scores=[96.66666666666667, 96.66666666666667, 100.0, 93.33333333333333, 90.0]'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mean accuracy=95.33333333333334'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import seed, randrange\n",
    "from math import sqrt, exp, pi\n",
    "from csv import reader\n",
    "\n",
    "\n",
    "seed(42)\n",
    "\n",
    "\n",
    "def load_csv(filepath):\n",
    "  dataset = []\n",
    "\n",
    "  with open(filepath, \"r\") as file:\n",
    "    csv_reader = reader(file)\n",
    "    for row in csv_reader:\n",
    "      if row:\n",
    "        dataset.append(row)\n",
    "  \n",
    "  return dataset\n",
    "\n",
    "\n",
    "def str_col_to_float(dataset, col):\n",
    "  for row in dataset:\n",
    "    row[col] = float(row[col].strip())\n",
    "\n",
    "\n",
    "def str_col_to_int(dataset, col):\n",
    "  class_vals = set(list(map(lambda row: row[col], dataset)))\n",
    "  class_idx_map = dict()\n",
    "\n",
    "  for idx, cv in enumerate(class_vals):\n",
    "    class_idx_map[cv] = idx\n",
    "  for row in dataset:\n",
    "    row[col] = class_idx_map[row[col]]\n",
    "\n",
    "\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "  dataset_folds = []\n",
    "  fold_size = int(len(dataset) / n_folds)\n",
    "  dataset_ = dataset.copy()\n",
    "\n",
    "  for _ in range(n_folds):\n",
    "    fold = []\n",
    "    while len(fold) < fold_size:\n",
    "      fold.append(dataset_.pop(randrange(len(dataset_))))\n",
    "    dataset_folds.append(fold)\n",
    "  \n",
    "  return dataset_folds\n",
    "\n",
    "\n",
    "def accuracy_metric(actual, predicted):\n",
    "  assert len(actual) == len(predicted)\n",
    "\n",
    "  size = len(actual)\n",
    "  correct_count = 0\n",
    "\n",
    "  for i in range(size):\n",
    "    correct_count += 1 if actual[i] == predicted[i] else 0\n",
    "  \n",
    "  return (correct_count / float(size)) * 100\n",
    "\n",
    "\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "  folds = cross_validation_split(dataset=dataset, n_folds=n_folds)\n",
    "  scores = []\n",
    "\n",
    "  for fold in folds:\n",
    "    train = folds.copy()\n",
    "    train.remove(fold)\n",
    "    train = sum(train, [])\n",
    "    test = []\n",
    "    for row in fold:\n",
    "      row_ = row.copy()\n",
    "      row_[-1] = None\n",
    "      test.append(row_)\n",
    "    predicted = algorithm(train, test, *args)\n",
    "    actual = list(map(lambda row: row[-1], fold))\n",
    "    accuracy = accuracy_metric(actual=actual, predicted=predicted)\n",
    "    scores.append(accuracy)\n",
    "  \n",
    "  return scores\n",
    "\n",
    "\n",
    "def separate_by_class(dataset):\n",
    "  rows_by_class = {}\n",
    "  \n",
    "  for i in range(len(dataset)):\n",
    "    class_val = dataset[i][-1]\n",
    "    if class_val not in rows_by_class:\n",
    "      rows_by_class[class_val] = []\n",
    "    rows_by_class[class_val].append(dataset[i])\n",
    "  \n",
    "  return rows_by_class\n",
    "\n",
    "\n",
    "def mean(numbers):\n",
    "  return sum(numbers) / len(numbers)\n",
    "\n",
    "\n",
    "def stddev(numbers):\n",
    "  avg = mean(numbers)\n",
    "  \n",
    "  variance = sum(list(map(lambda x: pow(x - avg, 2), numbers))) / float(len(numbers) - 1)\n",
    "  \n",
    "  return sqrt(variance)\n",
    "\n",
    "\n",
    "def summarize_dataset(dataset):\n",
    "  summaries = [(mean(col), stddev(col), len(col)) for col in zip(*dataset)]\n",
    "  \n",
    "  del(summaries[-1])\n",
    "\n",
    "  return summaries\n",
    "\n",
    "\n",
    "def summarize_by_class(dataset):\n",
    "  separated = separate_by_class(dataset=dataset)\n",
    "  summaries = {}\n",
    "\n",
    "  for class_val, rows in separated.items():\n",
    "    summaries[class_val] = summarize_dataset(dataset=rows)\n",
    "  \n",
    "  return summaries\n",
    "\n",
    "\n",
    "def gaussian_pdf(x, mean_val, stddev_val):\n",
    "  exponent = exp(-((x - mean_val) ** 2 / (2 * stddev_val ** 2)))\n",
    "  \n",
    "  return (1 / (sqrt(2 * pi) * stddev_val)) * exponent\n",
    "\n",
    "\n",
    "def calculate_class_probabilities(summaries, row):\n",
    "  n_rows = sum([summaries[label][0][2] for label in summaries])\n",
    "  probabilities = {}\n",
    "\n",
    "  for class_val, class_summaries in summaries.items():\n",
    "    probabilities[class_val] = summaries[class_val][0][2] / float(n_rows)\n",
    "    for i in range(len(class_summaries)):\n",
    "      mean_val, stddev_val, _ = class_summaries[i]\n",
    "      probabilities[class_val] *= gaussian_pdf(x=row[i], mean_val=mean_val, stddev_val=stddev_val)\n",
    "  \n",
    "  return probabilities\n",
    "\n",
    "\n",
    "def predict(summaries, row):\n",
    "  probabilities = calculate_class_probabilities(summaries=summaries, row=row)\n",
    "  best_label, best_prob = None, -1\n",
    "\n",
    "  for class_val, probability in probabilities.items():\n",
    "    if best_label is None or probability > best_prob:\n",
    "      best_prob = probability\n",
    "      best_label = class_val\n",
    "  \n",
    "  return best_label\n",
    "\n",
    "\n",
    "def naive_bayes(train, test):\n",
    "  summaries = summarize_by_class(dataset=train)\n",
    "  predictions = []\n",
    "  \n",
    "  for row in test:\n",
    "    predictions.append(predict(summaries=summaries, row=row))\n",
    "  \n",
    "  return predictions\n",
    "\n",
    "\n",
    "filepath = \"../datasets/iris.csv\"\n",
    "dataset = load_csv(filepath=filepath)\n",
    "for i in range(len(dataset[0]) - 1):\n",
    "  str_col_to_float(dataset=dataset, col=i)\n",
    "str_col_to_int(dataset=dataset, col=len(dataset[0]) - 1)\n",
    "n_folds = 5\n",
    "scores = evaluate_algorithm(dataset, naive_bayes, n_folds)\n",
    "display(f\"scores={scores}\")\n",
    "display(f\"mean accuracy={sum(scores) / len(scores)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d90add59a33e9f0fdc2a403872f22c3f38cf2bdffc6f1ab0ac261e13b4722f13"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
